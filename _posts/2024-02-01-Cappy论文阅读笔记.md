---
layout:     post   				    # 使用的布局（不需要改）
title:      《Cappy: Outperforming and Boosting Large Multi-Task LMs with a Small Scorer》-论文阅读笔记              # 标题 
subtitle:   Cappy	                # 副标题
date:       2024-02-01 				# 时间
author:     BY Handx				# 作者
header-img: img/a7d6988001f845fc91101cb04f67c290_0.jpg 	#这篇文章标题背景图片
catalog: true 						# 是否归档
tags:								#标签
    - 大模型
    - 大模型插件-pipline
---

# Cappy-阅读笔记

### 简介：

​	在2023年神经信息处理系统大会（NeurIPS）上，卡内基梅隆大学（Carnegie Mellon University）以及谷歌研究院（Google Research）等权威研究机构的研究论文中指出，尽管大型模型展现出了在应对各种任务时的卓越通用性和泛化能力，但这些模型通常所拥有的网络参数量高达数十亿乃至数百亿级别，这一特性使得在进行模型训练和推理操作的过程中，不可避免地会消耗极其庞大的计算资源。

​	在实际应用中，要求单个多任务大模型以零样本或小样本学习的方式解决所有类型的任务是一项颇具挑战性的目标，特别是在处理那些复杂性较高、具有显著个性化特征且无法仅通过简洁指令精确刻画的任务时。另一方面，常规的下游训练数据集通常规模有限，难以单独提供充分而广泛的先验知识输入以实现对模型的深度与全面训练。

​	因此，针对不同的下游任务对多任务大模型进行有监督的微调是解决这一问题的关键策略之一。然而，在实施模型微调时，确实存在一些挑战和问题：

​	（1）为每个下游任务维护一个独立的LLM副本所需的大量存储空间.

​	（2）对GPU/TPU的内存需求显著增加，

​	（3）更加强大的多任务LLMs（如OPT-IML-175B 和FLAN-PaLM-540B ）往往不可获取。

​	尽管诸如prefix-tuning、LoRA等高效参数微调策略在一定程度上大幅削减了存储需求，但它们仍需要在调整过程中通过大型语言模型（LLM）的参数进行反向传播训练。与此同时，另外一些采用上下文学习（in-context learning）的方法，则试图通过将有限数量的监督示例直接嵌入指令中来避免显式的参数调整步骤。然而，此类方法受限于模型的最大输入长度限制，这意味着它们仅能利用有限的样本对任务解决过程提供指导，从而在处理复杂度较高或数据量较大的场景时可能面临局限性。

​	面对参数优化与存储效率的双重挑战，作者创新性地研发了一种基于RoBERTa框架构建的小型预训练评估模型——Cappy，其具有精简的3.6亿个参数规模，在保持优异性能基准的同时显著降低了硬件资源需求。Cappy的核心机制在于接纳一组指令及其相应的候选回答输入，并精准地输出一个介于0至1之间的分数，该分数反映模型对候选回答正确执行指令的概率判断，从而有力支持对响应品质的准确评估与筛选。

​	在实际应用中，Cappy不仅能够独立承担分类任务的角色，而且在与大型语言模型协同运作时，还能扮演重要辅助角色：它能有效辅助现有的多任务大型语言模型（LLMs），从LLM生成的一系列候选输出中甄别并选出最为贴切和恰当的答案。

### 论文方法

​	**任务类型**：回归任务

​	设计者借鉴了RoBERTa架构，并在模型的顶层结构中巧妙地融入了一个专门的线性回归模块。模型的核心运行机制是这样的：在输入端，它接受一对文本数据，即指令和相应的响应；而在输出端，则生成一个范围在0到1之间的连续数值评分。这个分数具有显著的意义：数值越接近1，意味着候选响应相对于指令所设定的任务目标越精确、越贴切。通过这样的设计方案，该分数明确代表了模型对特定指令指向的任务实例下，候选响应成功执行或满足指令要求的概率估计程度，从而为量化评估和衡量响应的质量提供了精确而严谨的标准依据（如下图所示）。

![cabby_模型图.png](https://s2.loli.net/2024/02/05/VRzPAvhFileNTsa.png)

​	**数据集的构建**：

1. **人工或半自动生成错误响应**：通过人为设计或使用规则、模型生成技术来创造与指令对应的多种可能的错误或部分正确的响应，并根据其与真实响应的匹配程度赋予相应介于0至1之间的正确性得分。
2. **噪声注入**：对真实响应进行微调，如随机删除、替换或插入词语，以模拟可能出现的错误情况，同时依据修改后的响应偏离真实值的程度分配正确性得分。
3. **混合不同难度级别数据**：整合来自不同任务难度级别的数据，确保既有容易解决的任务也有较难的任务，这样模型不仅能够学习到完全正确和完全错误的情况，还能处理不同程度上的模糊性和不确定性。
4. **完全匹配**和**完全不匹配**。
5. 通过数据增强生成**指令-响应**对，并使用**Rouge-L**作为指标计算相似性。
